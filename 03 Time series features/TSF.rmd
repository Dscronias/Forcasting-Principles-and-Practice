# Time series decomposition

```{r, include = FALSE}
# Libraries
library(tidyverse)
library(tsibble)
library(fpp3)
library(knitr)
library(svglite)
library(ggthemes)
library(lemon)
library(USgas)
library(glue)
library(broom)

# Datasets
olympic_running <- tsibbledata::olympic_running
pbs <- tsibbledata::PBS
vic_elec <- tsibbledata::vic_elec
tourism <- tsibble::tourism
aus_production <- tsibbledata::aus_production
gafa_stock <- tsibbledata::gafa_stock
pelt <- tsibbledata::pelt
aus_arrivals <- fpp3::aus_arrivals
aus_retail <- tsibbledata::aus_retail
us_employment <- fpp3::us_employment
global_economy <- tsibbledata::global_economy
aus_livestock <- tsibbledata::aus_livestock

# Functions

## Get the lambda for a Box-Cox transformation
## using the Guerrero method
get_boxcox_lambda <- function(df, var) {
  df %>%
  features(df[, var], features = guerrero) %>%
  pull(lambda_guerrero)
}

# Parameters
kable_length <- 5
svg_res <- 144

# GGplot graphical style
theme_set(
  theme_tufte() +
  theme(
    axis.line = element_line(colour = "black", size = rel(1))
  )
)
short_axis <- function(baxis = "both", laxis = "both") {
  return(lemon::coord_capped_cart(bottom = baxis, left = laxis))
}
```

## Some simple statistics

```{r}
tourism %>%
  features(Trips, list(mean = mean)) %>%
  arrange(mean)
```

Is this just a way to do summarise()?
Plus, it returns a tibble, not a tsibble. (Understandable, since we don't have a time component anymore)

```{r}
tourism %>%
  group_by(Region, State, Purpose) %>%
  summarise(Trips = mean(Trips)) %>%
  arrange(Trips)
```

Yeah, does not work.

```{r}
tourism %>%
  as_tibble() %>%
  group_by(Region, State, Purpose) %>%
  summarise(Trips = mean(Trips)) %>%
  arrange(Trips)
```

Better.

```{r}
tourism %>% features(Trips, list(
  mean = mean,
  quantile = quantile
  )
)
```

## ACF Features

```{r}
tourism %>% features(Trips, feat_acf)
```

Negative autocorrelations?
>> No, it just seems first differencing introduces negative autocorrelation. Plus, you can only do the diagnostic on the original series, not the time differenced one.
See: https://stats.stackexchange.com/questions/77593/why-does-differencing-time-series-introduce-negative-autocorrelation
And: https://people.duke.edu/~rnau/411arim2.htm 

```{r}
tourism %>%
  filter(Region == "Adelaide", State == "South Australia", Purpose == "Business") %>%
  ACF(Trips) %>%
  autoplot()
```

Doesn't seem really necessary to do some differencing.

## STL Features

```{r}
tourism %>%
  features(Trips, feat_stl)
```

```{r}
tourism %>%
  features(Trips, feat_stl) %>%
  ggplot(aes(x = trend_strength, y = seasonal_strength_year,
             col = Purpose)) +
  geom_point() +
  facet_wrap(vars(State))
```

Super nice

```{r}
tourism %>%
  features(Trips, feat_stl) %>%
  filter(
    seasonal_strength_year == max(seasonal_strength_year)
  ) %>%
  left_join(tourism, by = c("State", "Region", "Purpose")) %>%
  ggplot(aes(x = Quarter, y = Trips)) +
  geom_line() +
  facet_grid(vars(State, Region, Purpose))
```

## Exploring Australian tourism data

```{r}
tourism_features <- tourism %>%
  features(Trips, feature_set(pkgs = "feasts"))
tourism_features
```

```{r}
tourism_features %>%
  select_at(vars(contains("season"), Purpose)) %>%
  mutate(
    # * Seems the 4*(x == 0) ==> 4*TRUE ==> 4*1
    # * find it a bit weird, but alright
    seasonal_peak_year = seasonal_peak_year +
      4 * (seasonal_peak_year == 0),
    seasonal_trough_year = seasonal_trough_year +
      4 * (seasonal_trough_year == 0),
    # * Nice, need to remember this package
    seasonal_peak_year = glue("Q{seasonal_peak_year}"),
    seasonal_trough_year = glue("Q{seasonal_trough_year}"),
  ) %>%
  GGally::ggpairs(mapping = aes(colour = Purpose))
```

```{r}
pcs <- tourism_features %>%
  select(-State, -Region, -Purpose) %>%
  prcomp(scale = TRUE)

# Eigenvalue
pcs$sdev^2 %>% as_tibble() %>% rename(Eigenvalues = value)
# Explained variance
pcs$sdev^2 %>% as_tibble() %>%
 mutate(value = value / 47) %>%
 rename(Eigenvalues = value)

pcs <- pcs %>% augment(tourism_features)
```

It seemed a bit weird at first to do a PCA on that. But hey, why not.

```{r}
pcs %>%
  ggplot(aes(x = .fittedPC1, y = .fittedPC2, col = Purpose)) +
  geom_point() +
  theme(aspect.ratio = 1)
```

```{r}
outliers <- pcs %>%
  filter(.fittedPC1 > 10) %>%
  select(Region, State, Purpose, .fittedPC1, .fittedPC2)
outliers
```

Nice way to detect outliers, actually. Try with with LOF for comparison, maybe?
Not sure why I don't have the same results?

```{r}
outliers %>%
  left_join(tourism, by = c("State", "Region", "Purpose")) %>%
  mutate(
    # Nice
    Series = glue("{State}", "{Region}", "{Purpose}",
                  .sep = "\n\n")
  ) %>%
  ggplot(aes(x = Quarter, y = Trips)) +
  geom_line() +
  facet_grid(Series ~ ., scales = "free") +
  labs(title = "Outlying time series in PC space")
```

## Exercises

```{r}
pbs_cost_summary <- pbs %>%
  features(Cost, list(
    # ~ is for anonymous functions with purrr
    Mean = ~ mean(.),
    SD = ~ sd(.)
  ))

pbs_highest_mean <- pbs_cost_summary %>%
  filter(Mean == max(Mean)) %>%
  select(Concession, Type, ATC1, ATC2) %>%
  left_join(pbs, by = c("Concession", "Type", "ATC1", "ATC2")) %>%
  as_tsibble(key = c("Concession", "Type", "ATC1", "ATC2"), index = Month)
pbs_lowest_sd <- pbs_cost_summary %>%
  filter(SD > 0) %>%
  filter(SD == min(SD)) %>%
  select(Concession, Type, ATC1, ATC2) %>%
  left_join(pbs, by = c("Concession", "Type", "ATC1", "ATC2")) %>%
  as_tsibble(key = c("Concession", "Type", "ATC1", "ATC2"), index = Month)
```

```{r}
pbs_highest_mean %>%
  autoplot(Cost)
```

Nice

```{r}
pbs_lowest_sd %>%
  autoplot(Cost)
```

Not much data there.

2. Tourism

```{r}
tourism_holiday_features <- tourism %>%
  filter(Purpose == "Holiday") %>%
  group_by(State) %>%
  summarise(Trips = sum(Trips)) %>%
  features(Trips, feature_set(pkgs = "feasts")) %>%
  mutate(
    seasonal_peak_year = seasonal_peak_year +
      4 * (seasonal_peak_year == 0),
    seasonal_trough_year = seasonal_trough_year +
      4 * (seasonal_trough_year == 0),
    seasonal_peak_year = glue("Q{seasonal_peak_year}") %>% as_factor(),
    seasonal_trough_year = glue("Q{seasonal_trough_year}") %>% as_factor(),
  )
```

```{r}
tourism_holiday_features %>%
  select(State, seasonal_peak_year) %>%
  kable()
```

3. Outliers in PBS

```{r}
pbs_features <- pbs %>%
  features(Cost, feature_set(pkgs = "feasts")) %>%
  drop_na()
```

```{r}
# seasonal_peak_year and seasonal_trough_year are categorical variables.
# ndiffs and nsdiffs are binary.
# We can't normalize them, it wouldn't make sense.

pbs_features_pca <- pbs_features %>%
  select(
    -seasonal_peak_year, -seasonal_trough_year, -ndiffs,
    -nsdiffs, -Concession, -Type, -ATC1, -ATC2
  ) %>%
  mutate(
    across(
      !where(is.character),
      ~ scale(.)
    )
  ) %>%
  prcomp()
```

```{r}
# Eigenvalue
pbs_features_pca$sdev^2 %>% as_tibble() %>% rename(Eigenvalues = value)
# Explained variance
pbs_features_pca$sdev^2 %>% as_tibble() %>%
 mutate(value = value / 47 * 100) %>%
 rename(`Eigenvalues (%)`= value)

# TODO: put that on a graph
pbs_features_pca$rotation %>% as_tibble() %>% select(PC1, PC2)
```

```{r}
pbs_features_pca %>%
  augment(pbs_features) %>%
  select(
    Concession, Type, ATC1, ATC2, starts_with(".fitted")
  ) %>%
  ggplot(aes(x = .fittedPC1, y = .fittedPC2)) +
  geom_point()
```

I could achieve better things using clustering methods on the first ten components (~77% of the variance), but I am lazy at the moment.
Also I could just use LOF.

```{r}
pbs_features_pca %>%
  augment(pbs_features) %>%
  select(
    Concession, Type, ATC1, ATC2, starts_with(".fitted")
  ) %>% 
  filter(.fittedPC2 < -10) %>%
  left_join(pbs, c("Concession", "Type", "ATC1", "ATC2")) %>%
  as_tsibble(key = c("Concession", "Type", "ATC1", "ATC2"), index = Month) %>%
  mutate(
    Series = glue("{Concession}", "{Type}", "{ATC1}", "{ATC2}",
                  .sep = "\n\n")
  ) %>%
  ggplot(aes(x = Month, y = Cost)) +
  geom_line() +
  facet_grid(Series ~ ., scales = "free") +
  labs(title = "Outlying time series in PC space")
```

Just observations with a lot of zeros.